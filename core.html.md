# API


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L13"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML

>      NVML ()

*Convenient access to `pynvml` (the library behind `nvidia-smi`)*

``` python
nv = NVML()
nv.driver_version, nv.cuda_version
```

    ('535.183.06', '12.2')

``` python
handle = nv[0]
nvmlDeviceGetName(handle)
```

    'NVIDIA RTX A6000'

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L32"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.info

>      NVML.info (i:int=0)

*Basic information about GPU `i`*

``` python
nv.info(0)
```

    _Info(name='NVIDIA RTX A6000', serial='1322123048138', uuid='GPU-61e56e6f-2a64-c0f4-b26c-ab3ead0eed5b', persistence_mode=1, bus_id='00000000:01:00.0', display_active=0, performance_state=8, fan_speed=30, temperature=31, compute_mode=0)

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L53"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.mem

>      NVML.mem (i:int=0)

*Memory total/free/used for GPU `i`, in MB*

``` python
nv.mem(0)
```

    _Memory(free=2193.25, total=49140.0, used=46946.75)

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L64"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.utilization

>      NVML.utilization (i:int=0)

*% of time during which GPU `i` was actively using various components*

``` python
nv.utilization(0)
```

    _Utilization(gpu=0, memory=0, enc=0, dec=0)

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L78"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.power

>      NVML.power (i:int=0)

*Get power usage and limit for GPU `i` in watts*

``` python
nv.power(0)
```

    _Power(usage=16.866, limit=300.0)

Here “limit” refers to the maximum power draw allowed for the GPU.

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L90"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.clocks

>      NVML.clocks (i:int=0)

*Get current clock speeds (in MHz) for GPU `i`*

``` python
nv.clocks(0)
```

    _Clocks(graphics=0, sm=0, mem=405)

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L104"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.pcie_throughput

>      NVML.pcie_throughput (i:int=0)

*Get PCIe throughput (in KB/s) for GPU `i`*

``` python
nv.pcie_throughput(0)
```

    _PCIeThroughput(rx=0.0, tx=0.0)

1.  “rx” represents receive - data flowing from the motherboard to the
    GPU.
2.  “tx” represents transmit - data flowing from the GPU to the
    motherboard.

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L120"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.processes

>      NVML.processes (i:int=0)

*Get information about processes running on GPU `i`*

``` python
nv.processes(0)
```

    [_ProcessInfo(pid=201084, name='/home/jhoward/miniconda3/bin/python3.12', memory=46476.0)]

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/py-smi/blob/main/py_smi/core.py#L132"
target="_blank" style="float:right; font-size:smaller">source</a>

### NVML.dmon

>      NVML.dmon (i:int=0)

*Get key monitoring metrics for GPU `i`, similar to `nvidia-smi dmon`*

``` python
nv.dmon(0)
```

    _DMon(pwr=16.866, gtemp=31, sm=0, mem=0, enc=0, dec=0, mclk=405, pclk=0)
